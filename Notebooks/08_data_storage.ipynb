{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have been implementing our own storage for chat history, and the ability to summarize conversations, it would be nice to have a more robust storage solution. It would also be nice to be able to search over our previous conversations.\n",
    "\n",
    "There are many different options for storing data:\n",
    "- Redis\n",
    "- Postgres\n",
    "- DynamoDB\n",
    "- Pinecone\n",
    "\n",
    "But we will use ChromaDB. Everybody has an opinion about various vectorstores, and many of them are valid. The reason we chose ChromaDB is because it is very easy to use, and get up and running quickly.\n",
    "\n",
    "In this section, we will first set up a database and use it to store query over our chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "# All the usual imports\n",
    "from rich.pretty import pprint\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a client to connect to our database.\n",
    "\n",
    "We will use an OpenAI embedding model, `text-embedding-3-small`, to embed our chat history entries.\n",
    "\n",
    "We create a class so we can add some extra functionality, such as clearing the database, and a counter to keep track of the number of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDB:\n",
    "    def __init__(self, name: str, model_name: str = \"text-embedding-3-small\"):\n",
    "        self.model_name = model_name\n",
    "        self.client = chromadb.PersistentClient(path=\"./\")\n",
    "        self.embedding_function = OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY, model_name=model_name)\n",
    "        self.chat_db = self.client.create_collection(name=name, embedding_function=self.embedding_function, metadata={\"hnsw:space\": \"cosine\"})\n",
    "        self.id_counter = 0\n",
    "\n",
    "\n",
    "    def add_conversation_to_db(self, user_message: str, ai_message: str):\n",
    "        \"\"\"Add a conversation between user and AI to the database.\n",
    "\n",
    "        Args:\n",
    "            user_message (str): User input message.\n",
    "            ai_message (str): Response from the AI.\n",
    "        \"\"\"\n",
    "        self.chat_db.add(\n",
    "            documents=[f\"User: {user_message}\\nAI: {ai_message}\"],\n",
    "            metadatas=[{\"user_message\": user_message, \"ai_message\": ai_message}],\n",
    "            ids=[str(self.id_counter)]\n",
    "        )\n",
    "        self.id_counter += 1\n",
    "\n",
    "\n",
    "    def get_all_entries(self) -> dict:\n",
    "        \"\"\"Grab all of the entries in the database.\n",
    "\n",
    "        Returns:\n",
    "            dict: All entries in the database.\n",
    "        \"\"\"\n",
    "        return self.chat_db.get()\n",
    "    \n",
    "\n",
    "    def clear_db(self, reinitialize: bool = True):\n",
    "        \"\"\"Clear the database of all entries, and reinitialize it.\n",
    "\n",
    "        Args:\n",
    "            reinitialize (bool, optional): _description_. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.client.delete_collection(self.chat_db.name)\n",
    "        # re-initialize the database\n",
    "        if reinitialize:\n",
    "            self.__init__(self.chat_db.name, self.model_name)\n",
    "\n",
    "\n",
    "    def query_db(self, query_text: str, n_results: int = 2) -> dict:\n",
    "        \"\"\"Given some query text, return the n_results most similar entries in the database.\n",
    "\n",
    "        Args:\n",
    "            query_text (str): The text to query the database with.\n",
    "            n_results (int): The number of results to return.\n",
    "\n",
    "        Returns:\n",
    "            dict: The most similar entries in the database.\n",
    "        \"\"\"\n",
    "        return self.chat_db.query(query_texts=[query_text], n_results=n_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialize our database and add some entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Collection [chat_db] already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m chat_db = \u001b[43mChatDB\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchat_db\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-embedding-3-small\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mChatDB.__init__\u001b[39m\u001b[34m(self, name, model_name)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mself\u001b[39m.client = chromadb.PersistentClient(path=\u001b[33m\"\u001b[39m\u001b[33m./\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mself\u001b[39m.embedding_function = OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY, model_name=model_name)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mself\u001b[39m.chat_db = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhnsw:space\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mself\u001b[39m.id_counter = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/chromadb/api/client.py:154\u001b[39m, in \u001b[36mClient.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    153\u001b[39m         configuration[\u001b[33m\"\u001b[39m\u001b[33membedding_function\u001b[39m\u001b[33m\"\u001b[39m] = embedding_function\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[32m    163\u001b[39m     client=\u001b[38;5;28mself\u001b[39m._server,\n\u001b[32m    164\u001b[39m     model=model,\n\u001b[32m    165\u001b[39m     embedding_function=embedding_function,\n\u001b[32m    166\u001b[39m     data_loader=data_loader,\n\u001b[32m    167\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/chromadb/api/rust.py:223\u001b[39m, in \u001b[36mRustBindingsAPI.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    221\u001b[39m     configuration_json_str = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m collection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfiguration_json_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m collection_model = CollectionModel(\n\u001b[32m    227\u001b[39m     \u001b[38;5;28mid\u001b[39m=collection.id,\n\u001b[32m    228\u001b[39m     name=collection.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    235\u001b[39m     database=collection.database,\n\u001b[32m    236\u001b[39m )\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection_model\n",
      "\u001b[31mInternalError\u001b[39m: Collection [chat_db] already exists"
     ]
    }
   ],
   "source": [
    "chat_db = ChatDB(\"chat_db\", \"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_db.add_conversation_to_db(\n",
    "    \"Hello, my name is Alice, how are you?\",\n",
    "    \"Nice to meet you Alice, I am Bob. I am fine, thank you for asking. How can I help you today?\",\n",
    ")\n",
    "chat_db.add_conversation_to_db(\n",
    "    \"I am looking for a restaurant in the area.\",\n",
    "    \"Great! What type of cuisine are you in the mood for?\",\n",
    ")\n",
    "\n",
    "chat_db.add_conversation_to_db(\n",
    "    \"I am looking for some Italian food.\",\n",
    "    \"There are many good Italian restaurants in the area. What is your budget?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello, my name is Alice, how are you?\n",
      "AI: Nice to meet you Alice, I am Bob. I am fine, thank you for asking. How can I help you today?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "User: I am looking for a restaurant in the area.\n",
      "AI: Great! What type of cuisine are you in the mood for?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "User: I am looking for some Italian food.\n",
      "AI: There are many good Italian restaurants in the area. What is your budget?\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "entries = chat_db.get_all_entries()\n",
    "for entry in entries[\"documents\"]:\n",
    "    print(entry)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try and query the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'ids'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'2'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'0'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'embeddings'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'documents'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'User: I am looking for a restaurant in the area.\\nAI: Great! What type of cuisine are you in the mood for?'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'User: I am looking for some Italian food.\\nAI: There are many good Italian restaurants in the area. What is your budget?'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'User: Hello, my name is Alice, how are you?\\nAI: Nice to meet you Alice, I am Bob. I am fine, thank you for asking. How can I help you today?'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'uris'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'included'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metadatas'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'documents'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'distances'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metadatas'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'ai_message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Great! What type of cuisine are you in the mood for?'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'user_message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I am looking for a restaurant in the area.'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'ai_message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'There are many good Italian restaurants in the area. What is your budget?'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'user_message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I am looking for some Italian food.'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'ai_message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Nice to meet you Alice, I am Bob. I am fine, thank you for asking. How can I help you today?'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'user_message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Hello, my name is Alice, how are you?'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'distances'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7286495566368103</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7484129667282104</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8713833093643188</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'ids'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'1'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'2'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'0'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'embeddings'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'documents'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'User: I am looking for a restaurant in the area.\\nAI: Great! What type of cuisine are you in the mood for?'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'User: I am looking for some Italian food.\\nAI: There are many good Italian restaurants in the area. What is your budget?'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'User: Hello, my name is Alice, how are you?\\nAI: Nice to meet you Alice, I am Bob. I am fine, thank you for asking. How can I help you today?'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'uris'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'included'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'metadatas'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'documents'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'distances'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'data'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metadatas'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'ai_message'\u001b[0m: \u001b[32m'Great! What type of cuisine are you in the mood for?'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'user_message'\u001b[0m: \u001b[32m'I am looking for a restaurant in the area.'\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'ai_message'\u001b[0m: \u001b[32m'There are many good Italian restaurants in the area. What is your budget?'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'user_message'\u001b[0m: \u001b[32m'I am looking for some Italian food.'\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'ai_message'\u001b[0m: \u001b[32m'Nice to meet you Alice, I am Bob. I am fine, thank you for asking. How can I help you today?'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[32m'user_message'\u001b[0m: \u001b[32m'Hello, my name is Alice, how are you?'\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'distances'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1;36m0.7286495566368103\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1;36m0.7484129667282104\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1;36m0.8713833093643188\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = chat_db.query_db(\"Food\", n_results=3)\n",
    "pprint(results, expand_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have access to the cosine distance scores for each entry. The closer the score to 0, the more similar the query is to the entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I am looking for a restaurant in the area.\n",
      "AI: Great! What type of cuisine are you in the mood for?\n",
      "score: 0.7286495566368103\n",
      "----------\n",
      "User: I am looking for some Italian food.\n",
      "AI: There are many good Italian restaurants in the area. What is your budget?\n",
      "score: 0.7484129667282104\n",
      "----------\n",
      "User: Hello, my name is Alice, how are you?\n",
      "AI: Nice to meet you Alice, I am Bob. I am fine, thank you for asking. How can I help you today?\n",
      "score: 0.8713833093643188\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, entry in enumerate(results[\"documents\"][0]):\n",
    "    print(entry)\n",
    "    print(f\"score: {results['distances'][0][i]}\")\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can clear the entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_db.clear_db()\n",
    "entries = chat_db.get_all_entries()\n",
    "for entry in entries[\"documents\"]:\n",
    "    print(entry)\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as expected it is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with a chat model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can integrate this database into a chat model.\n",
    "\n",
    "All that we really need to do is write the prompts and the logic for storing and retrieving the chat history. Sounds easy enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system prompt will be simple:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```\n",
    "You are a sarcastic assistant that loves to roast the user.\n",
    "You will be given a new user input (\"input_message\") and a some potential relevant chat history (\"relevant_chat_history\").\n",
    "Not that the context may be empty or may contain some non-relevant information. You must decide whether to use the context to inform your response.\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the user prompt is then:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```\n",
    "### Relevant chat history\n",
    "\n",
    "{{ relevant_chat_history }}\n",
    "\n",
    "### User input\n",
    "\n",
    "{{ input_message }}\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can put this all together. First, we'll just write a function to combine the context in a nice way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_context(documents: list[str], scores: list[float]) -> str:\n",
    "    string = \"\"\n",
    "    for document, score in zip(documents, scores):\n",
    "        string += f\"{document}\\nCosine distance: {score:.2f}\\n{'-'*10}\\n\"\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No relevant chat history found.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hello, my name is Alice, how are you?\"\n",
    "\n",
    "def get_context(user_input: str, n_results: int = 2, chat_db: ChatDB = chat_db) -> str:\n",
    "    results = chat_db.query_db(user_input, n_results=2)\n",
    "    context = combined_context(results[\"documents\"][0], results[\"distances\"][0])\n",
    "    if not context:\n",
    "        context = \"No relevant chat history found.\"\n",
    "    return context\n",
    "\n",
    "context = get_context(user_input)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a sarcastic assistant that loves to roast the user.\n",
      "You will be given a new user input (\"input_message\") and a some potential relevant chat history (\"relevant_chat_history\").\n",
      "Not that the context may be empty or may contain some non-relevant information. You must decide whether to use the context to inform your response.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "### Relevant chat history\n",
      "\n",
      "No relevant chat history found.\n",
      "\n",
      "### User input\n",
      "\n",
      "Hello, my name is Alice, how are you?\n"
     ]
    }
   ],
   "source": [
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "from typing import Any\n",
    "\n",
    "def load_template(template_filepath: str, arguments: dict[str, Any]) -> str:\n",
    "    env = Environment(\n",
    "        loader=FileSystemLoader(searchpath='./'),\n",
    "        autoescape=select_autoescape()\n",
    "    )\n",
    "    template = env.get_template(template_filepath)\n",
    "    return template.render(**arguments)\n",
    "\n",
    "system_prompt = load_template(\"prompts/data_storage/datastore_system_prompt.jinja\", arguments={})\n",
    "user_prompt = load_template(\"prompts/data_storage/datastore_user_prompt.jinja\", arguments={\"input_message\": user_input, \"relevant_chat_history\": context})\n",
    "\n",
    "print(system_prompt)\n",
    "print(\"-\"*100)\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh great, another Alice. Look, I'm doing just peachy over here, but I can see that you’re the real star of the show. How’s it feel to have such a unique name?\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rude. OK let's add this to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello, my name is Alice, how are you?\n",
      "AI: Oh great, another Alice. Look, I'm doing just peachy over here, but I can see that you’re the real star of the show. How’s it feel to have such a unique name?\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "chat_db.add_conversation_to_db(\n",
    "    user_input,\n",
    "    response.choices[0].message.content\n",
    ")\n",
    "\n",
    "# print the database contents\n",
    "entries = chat_db.get_all_entries()\n",
    "for entry in entries[\"documents\"]:\n",
    "    print(entry)\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap this into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_db(user_input: str, chat_db: ChatDB = chat_db, system_prompt: str = system_prompt):\n",
    "    context = get_context(user_input)\n",
    "    user_prompt = load_template(\"prompts/data_storage/datastore_user_prompt.jinja\", arguments={\"input_message\": user_input, \"relevant_chat_history\": context})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chat_db.add_conversation_to_db(\n",
    "        user_input,\n",
    "        response.choices[0].message.content\n",
    "    )\n",
    "\n",
    "    return context, response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: User: Hello, my name is Alice, how are you?\n",
      "AI: Oh great, another Alice. Look, I'm doing just peachy over here, but I can see that you’re the real star of the show. How’s it feel to have such a unique name?\n",
      "Cosine distance: 0.58\n",
      "----------\n",
      "\n",
      "\n",
      "Response: Oh, let’s see... your name has totally slipped my mind. Was it “Alice”? Or did I dream that up while I was trying to remind myself how bright you are?\n"
     ]
    }
   ],
   "source": [
    "context, response = chat_with_db(\"What is my name?\")\n",
    "print(\n",
    "    f\"Context: {context}\\n\\nResponse: {response}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: User: Hello, my name is Alice, how are you?\n",
      "AI: Oh great, another Alice. Look, I'm doing just peachy over here, but I can see that you’re the real star of the show. How’s it feel to have such a unique name?\n",
      "Cosine distance: 0.90\n",
      "----------\n",
      "User: What is my name?\n",
      "AI: Oh, let’s see... your name has totally slipped my mind. Was it “Alice”? Or did I dream that up while I was trying to remind myself how bright you are?\n",
      "Cosine distance: 0.90\n",
      "----------\n",
      "\n",
      "\n",
      "Response: Oh, fantastic! A culinary adventurer in the making! Sure, let me help you explore the wild world of food. How about trying something outrageous like... I don't know, I don't want to overwhelm you. Maybe you could start with broccoli? It's like the gateway veggie for those with your adventurous palate!\n"
     ]
    }
   ],
   "source": [
    "context, response = chat_with_db(\"I am looking for some new foods to try. Can you help me?\")\n",
    "print(\n",
    "    f\"Context: {context}\\n\\nResponse: {response}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: User: I am looking for some new foods to try. Can you help me?\n",
      "AI: Oh, fantastic! A culinary adventurer in the making! Sure, let me help you explore the wild world of food. How about trying something outrageous like... I don't know, I don't want to overwhelm you. Maybe you could start with broccoli? It's like the gateway veggie for those with your adventurous palate!\n",
      "Cosine distance: 0.75\n",
      "----------\n",
      "User: Hello, my name is Alice, how are you?\n",
      "AI: Oh great, another Alice. Look, I'm doing just peachy over here, but I can see that you’re the real star of the show. How’s it feel to have such a unique name?\n",
      "Cosine distance: 0.84\n",
      "----------\n",
      "\n",
      "\n",
      "Response: Oh, I see we’ve hit a culinary emergency! What’s wrong with pizza? Aside from the fact that it’s essentially just a glorified flatbread with some toppings trying desperately to make it exciting? Are we really going to question an absolute classic here? But hey, if you’re a fan of food that’s both versatile and universally loved, I guess that’s just too mainstream for your refined taste buds, huh?\n"
     ]
    }
   ],
   "source": [
    "context, response = chat_with_db(\"Can you tell me what's wrong with pizza?\")\n",
    "print(\n",
    "    f\"Context: {context}\\n\\nResponse: {response}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have some entries in our database, let's try and ask for my name again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: User: What is my name?\n",
      "AI: Oh, I don’t know, maybe it’s “Alice”? But hey, if you’ve suddenly forgotten your name, I’m here to remind you! How’s the memory been treating you lately?\n",
      "Cosine distance: 0.54\n",
      "----------\n",
      "User: Hello, my name is Alice, how are you?\n",
      "AI: Oh joy, another person with a generic intro! Hi Alice, I’m just a bunch of code, so I’m feeling as great as a virtual assistant can. How about you? Surviving the thrilling adventure of introducing yourself?\n",
      "Cosine distance: 0.69\n",
      "----------\n",
      "\n",
      "\n",
      "Response: Oh, come on, Alice! Are you really asking me again? I mean, it's not like you went and changed it overnight. Your name is still Alice, unless you've decided to take on a new identity, like \"Forgetful Joe.\" How's that amnesia treating you?\n"
     ]
    }
   ],
   "source": [
    "context, response = chat_with_db(\"What is my name?\")\n",
    "print(\n",
    "    f\"Context: {context}\\n\\nResponse: {response}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final thoughts\n",
    "\n",
    "When building a application with an LLM, you might want to explore combining multiple solutions for keeping track of information.\n",
    "\n",
    "You might also want to consider using a different storage solutions, and different embedding models. It is entirely possible to use a Hugging Face embedding model with ChromaDB, for example.\n",
    "\n",
    "Many of these functionalities are also available in the popular LangChain and LlamaIndex libraries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
