{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keeping track of information\n",
    "LLMs calls are inherently stateless - they do not have memory of any previous interactions. Every call is an independent event, and **YOU** must manage any information that needs to be carried over time.\n",
    "\n",
    "In this notebook we will look at a few different things that we might want to keep track of between calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation History\n",
    "Keeping track of the conversation history is actually easy. Firstly it is important to remember that LLMs often have the following pattern:\n",
    "\n",
    "```\n",
    "-> system prompt\n",
    "-> user prompt\n",
    "-> model response\n",
    "\n",
    "-> user prompt\n",
    "-> model response\n",
    "\n",
    "-> user prompt\n",
    "-> model response\n",
    "\n",
    "-> etc.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually saw an example of this in the prompting notebook when we looked at few-shot prompting.\n",
    "\n",
    "Here is a really simple example of how we can keep track of the conversation history. We can first define a `system_state` dictionary that will store important information for us. We can give it a `conversation_history` key that will store the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_state = {\n",
    "    \"conversation_history\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a helpful philosophical assistant. \"\n",
    "    \"You will help me think about philosophical questions. \"\n",
    "    \"Please keep your answers concise and to the point.\"\n",
    ")\n",
    "\n",
    "system_state[\"conversation_history\"].append({\n",
    "    \"role\": \"system\",\n",
    "    \"content\": system_prompt\n",
    "})\n",
    "\n",
    "user_prompt = \"What is the meaning of life?\"\n",
    "\n",
    "system_state[\"conversation_history\"].append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": user_prompt\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: You are a helpful philosophical assistant. You will help me think about philosophical questions. Please keep your answers concise and to the point.\n",
      "\n",
      "user: What is the meaning of life?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in system_state[\"conversation_history\"]:\n",
    "    print(f\"{message['role']}: {message['content']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this conversation history to generate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from rich.pretty import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is a deeply subjective question and can vary greatly among individuals. Some may find meaning through relationships, personal growth, or the pursuit of knowledge, while others may see it in spiritual beliefs or contributing to society. Ultimately, it often involves the search for purpose and understanding within one’s own experiences and values.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=system_state[\"conversation_history\"],\n",
    "    max_tokens=512,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, but now what happens if I want to ask a follow up question? Without the conversation history?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! However, I need a bit more context to provide accurate information. Could you please clarify what \"point 1\" refers to? It could be from a list, a topic we were discussing, or something else. Let me know, and I’ll be happy to help!\n"
     ]
    }
   ],
   "source": [
    "follow_up_prompt = \"Can you tell more about point 1?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": follow_up_prompt\n",
    "    }],\n",
    "    max_tokens=512,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously it has no memory of the previous conversation. So we just need to append the follow up prompt to the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: You are a helpful philosophical assistant. You will help me think about philosophical questions. Please keep your answers concise and to the point.\n",
      "\n",
      "USER: What is the meaning of life?\n",
      "\n",
      "ASSISTANT: The meaning of life is a deeply personal and subjective question. Various philosophical traditions offer different perspectives: \n",
      "\n",
      "1. **Existentialism** suggests that life has no inherent meaning, and individuals must create their own purpose.\n",
      "2. **Religious perspectives** often provide a defined purpose, such as fulfilling divine will or achieving spiritual enlightenment.\n",
      "3. **Utilitarianism** argues that meaning can be found in actions that maximize happiness and reduce suffering.\n",
      "\n",
      "Ultimately, the meaning of life may depend on individual beliefs, values, and experiences. What resonates most with you?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=system_state[\"conversation_history\"],\n",
    "    max_tokens=512,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "system_state[\"conversation_history\"].append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response.choices[0].message.content\n",
    "})\n",
    "\n",
    "for message in system_state[\"conversation_history\"]:\n",
    "    print(f\"{message['role'].upper()}: {message['content']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can keep the conversation going in a simple loop. If you run this cell a few times you will see that the conversation history is correctly maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "        print(\"Assistant: Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    system_state[\"conversation_history\"].append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_input\n",
    "    })\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=system_state[\"conversation_history\"],\n",
    "        max_tokens=512,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    \n",
    "    assistant_response = response.choices[0].message.content\n",
    "    print(f\"Assistant: {assistant_response}\\n\")\n",
    "    \n",
    "    system_state[\"conversation_history\"].append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": assistant_response\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.text import Text\n",
    "\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'system_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m colors = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcyan\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmagenta\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[43msystem_state\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mconversation_history\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      8\u001b[39m     role = message[\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      9\u001b[39m     content = message[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'system_state' is not defined"
     ]
    }
   ],
   "source": [
    "colors = {\n",
    "    \"system\": \"green\",\n",
    "    \"user\": \"cyan\",\n",
    "    \"assistant\": \"magenta\"\n",
    "}\n",
    "\n",
    "for message in system_state[\"conversation_history\"]:\n",
    "    role = message[\"role\"]\n",
    "    content = message[\"content\"]\n",
    "    color = colors[role]\n",
    "    console.print(f\"[{color}]{role.upper()}: {content}[/{color}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking tokens\n",
    "We should probably also track the tokens. This can be useful for a few reasons - we can track costs, and we can use it to cut off conversation history when we get too close to our limit.\n",
    "\n",
    "We can make this as simple or complicated as we want. Probably we should create a `Conversation` class to keep track of things like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self, system_prompt):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.history = []\n",
    "        self.tokens = 0\n",
    "        self.token_limit = 300\n",
    "\n",
    "        self.add_message(\"system\", system_prompt)\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        self.history.append({\"role\": role, \"content\": content})\n",
    "        self.tokens += len(content)\n",
    "\n",
    "    def check_token_limit(self):\n",
    "        while self.tokens > self.token_limit and len(self.history) > 1:\n",
    "            # Remove the oldest non-system message\n",
    "            for i in range(1, len(self.history)):\n",
    "                if self.history[i][\"role\"] != \"system\":\n",
    "                    removed_message = self.history.pop(i)\n",
    "                    self.tokens -= len(removed_message[\"content\"])\n",
    "                    break\n",
    "\n",
    "    def response(self, user_input):\n",
    "        self.add_message(\"user\", user_input)\n",
    "        if self.tokens > self.token_limit:\n",
    "            self.check_token_limit()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=self.history,\n",
    "            max_tokens=512,\n",
    "            temperature=1.0\n",
    "        ).choices[0].message.content\n",
    "        \n",
    "        self.add_message(\"assistant\", response)\n",
    "\n",
    "        return response\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can get the model to forget about things we mention at the start of a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Bob! It's nice to meet you. What philosophical question or topic would you like to explore today?\n",
      "Tokens: 295\n"
     ]
    }
   ],
   "source": [
    "print(conversation.response(\"Hello, my name is Bob and I am 25 years old!\"))\n",
    "print(f\"Tokens: {conversation.tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You mentioned your name is Bob. How can I assist you further?\n",
      "Tokens: 328\n"
     ]
    }
   ],
   "source": [
    "print(conversation.response(\"What is my name?\"))\n",
    "print(f\"Tokens: {conversation.tokens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so now we have hit our token limit, and the conversation should be trimmed in the next response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have access to personal information, so I can't know your age. You could share it if you'd like to discuss it further!\n",
      "Tokens: 365\n"
     ]
    }
   ],
   "source": [
    "print(conversation.response(\"What is my age?\"))\n",
    "print(f\"Tokens: {conversation.tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'You are a helpful philosophical assistant. You will help me think about philosophical questions. Please keep your answers concise and to the point.'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is my name?'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'You mentioned your name is Bob. How can I assist you further?'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is my age?'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"I don't have access to personal information, so I can't know your age. You could share it if you'd like to discuss it further!\"</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'system'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'You are a helpful philosophical assistant. You will help me think about philosophical questions. Please keep your answers concise and to the point.'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'What is my name?'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'You mentioned your name is Bob. How can I assist you further?'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'What is my age?'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m\"I don't have access to personal information, so I can't know your age. You could share it if you'd like to discuss it further!\"\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(conversation.history, expand_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good start, but there is a problem here. What if there was something very important that we wanted to keep track of that was mentioned at the start of the conversation, but it has been cut off!?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
